{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sqlalchemy import create_engine, text\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process 1 to Many relationship\n",
    "# Parameters: Original data frame and the col to be extracted/processed\n",
    "# Return: a list of original values (no duplicates)\n",
    "def rel_1M (original_df, col):\n",
    "    # extract the columns into a working data frame\n",
    "    processing_df = original_df[[col,'imdb_id']].dropna().reset_index()\n",
    "\n",
    "    # Create a list that holds dictionaries with data from the complex column\n",
    "    parent_data = []\n",
    "    update_data = []\n",
    "    # Loop as many times as rows there are in the working data frame\n",
    "    for idx in range(processing_df.shape[0]):       \n",
    "        # Extract the data of the 1 to M column (parameter)\n",
    "        col_str = processing_df[col][idx]         \n",
    "        # If column is evaluated as float, it means there is a NaN value and we skip it\n",
    "        col_str = col_str.replace('None', '\\'\\'')\n",
    "        # replace ' with \" to and jsonify it     \n",
    "        col_list = json.loads(col_str.replace('\\'', '\\\"'))  \n",
    "        # add the various values to a dictionary and the add then dictionary to a list\n",
    "        parent_data.append({'id':col_list['id'], 'name':col_list['name'], 'poster_path':col_list['poster_path'], \\\n",
    "                         'backdrop_path':col_list['backdrop_path']})\n",
    "        # The necessary entry in the original data (foreign key) is made\n",
    "        update_data.append({'id':col_list['id'], 'imdb_id':processing_df['imdb_id'][idx]})\n",
    "\n",
    "    # Deduplicate and turn the lists into dataframes\n",
    "    parent_data_df = pd.DataFrame(parent_data).drop_duplicates(subset={'id'})\n",
    "    update_data_df = pd.DataFrame(update_data).drop_duplicates(subset={'id','imdb_id'})\n",
    "            \n",
    "    # return the lists (this will become the parent table)\n",
    "    return parent_data_df, update_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process M to Many relationship\n",
    "# Parameters: Original data frame and the col to be extracted/processed\n",
    "# Return: \n",
    "#    1) Parent table - this will use all the original information in the column. It will be dedupped\n",
    "#    2) Association table - the id of the parent and the corresponding movie id (imdb_id)  \n",
    "def rel_MM (original_df, col):\n",
    "    # Create a list that holds dictionaries with data from the complex column\n",
    "    parent_data = []\n",
    "    # Create an association list with the id of the complex column and the movie id\n",
    "    associate_data = []\n",
    "    # Loop as many times as rows there are in the working data frame    \n",
    "    for idx in range(original_df.shape[0]):\n",
    "        # Extract the data of the M to M column (parameter)\n",
    "        col_str = original_df[col][idx]\n",
    "        # replace ' with \" to and jsonify it \n",
    "        col_list = json.loads(col_str.replace('\\'', '\\\"'))\n",
    "        # The column contains a list of dictionaries. Iterate the list to get the infromation out\n",
    "        for row in col_list:\n",
    "            # add the various values to a dictionary and then add the dictionary to a list (parent table)\n",
    "            parent_data.append({'id':row['id'], 'name':row['name']})\n",
    "            # add the various values to a dictionary and then add the dictionary to a list (association table)\n",
    "            associate_data.append({'id':row['id'], 'imdb_id':original_df['imdb_id'][idx]})\n",
    "    \n",
    "    # Deduplicate and turn the lists into dataframes\n",
    "    parent_data_df = pd.DataFrame(parent_data).drop_duplicates(subset={'id'})\n",
    "    associate_data_df = pd.DataFrame(associate_data).drop_duplicates(subset={'id','imdb_id'})\n",
    "    \n",
    "    # Return a dataframe with the parent and the association data\n",
    "    return parent_data_df, associate_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the path to the file\n",
    "csv_file = \"Data/movies_metadata.csv\"\n",
    "\n",
    "# Read the file into a dataframe\n",
    "movies_alldata_df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_connection_string = \"postgres:password@localhost:5432/movies_db\"\n",
    "engine = create_engine(f'postgresql://{rds_connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process 1 to M columns\n",
    "cols_1M_lst = [{'col': 'belongs_to_collection', 'table': 'collection', 'primary': 'collection_id'}]\n",
    "\n",
    "for col in cols_1M_lst:\n",
    "    parent_df, update_df = rel_1M (movies_alldata_df, col['col'])\n",
    "    \n",
    "    # Write parent data frame to the table\n",
    "    parent_df = parent_df.rename(columns={'id': col['primary']})\n",
    "    parent_df.to_sql(name=col['table'], con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save movies information\n",
    "# Extract the required columns\n",
    "movies_df = movies_alldata_df[['imdb_id', 'adult', 'budget', 'homepage', 'original_language', 'original_title', \\\n",
    "                               'overview', 'popularity', 'poster_path', 'release_date', 'revenue', 'runtime', \\\n",
    "                               'status', 'tagline', 'title', 'vote_average', 'vote_count']]\n",
    "\n",
    "\n",
    "# dedup in case there are duplicated movies\n",
    "movies_df = movies_df.drop_duplicates(subset={'imdb_id'})\n",
    "movies_df ['popularity'] = round(movies_df ['popularity'],4)\n",
    "# Write data frame to the table\n",
    "movies_df.to_sql(name='movie', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# use the update data frame to update the movies table\n",
    "update_df.to_sql(name='w_collec', con=engine, if_exists='replace', index=False)\n",
    "connection = engine.connect()\n",
    "result = connection.execute(\"update movie m \\\n",
    "                                set collection_id = (select id \\\n",
    "                                                       from w_collec w \\\n",
    "                                                      where w.imdb_id = m.imdb_id)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "production_company\n",
      "country\n",
      "spoken_languages\n"
     ]
    }
   ],
   "source": [
    "# Process M to M columns\n",
    "cols_MM_lst = [\n",
    "    {'col': 'genres', 'table': 'genre', 'primary': 'genre_id', 'assoc': 'film_genre'},\n",
    "    {'col': 'production_companies', 'table': 'production_company', 'primary': 'company_id', 'assoc': 'film_production_company'},\n",
    "    {'col': 'production_countries', 'table': 'country', 'primary': 'country_id', 'assoc': 'film_country'},\n",
    "    {'col': 'spoken_languages', 'table': 'spoken_languages', 'primary': 'lang_id', 'assoc': 'film_spoken_languages'}\n",
    "]\n",
    "\n",
    "for col in cols_MM_lst:\n",
    "    print(col['table'])\n",
    "    parent_df, associate_df = rel_MM (movies_alldata_df, col['col'])\n",
    "    # Write data frame to the table\n",
    "    parent_df = parent_df.rename(columns={'id': col['primary']})\n",
    "    parent_df.to_sql(name=col['table'], con=engine, if_exists='append', index=False)\n",
    "    associate_df = associate_df.rename(columns={'id': col['primary']})\n",
    "    associate_df.to_sql(name=col['assoc'], con=engine, if_exists='append', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script --output \"Movies_ETL\" Movies_ETL.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
