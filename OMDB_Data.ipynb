{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm_notebook\n",
    "import json\n",
    "from api_keys import api_key\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import csv of imdb_id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = \"Data/unique_indmID.csv\"\n",
    "imdb_id = pd.read_csv(imdb_data,skiprows=[1], low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_id = imdb_id['imdb_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions to parse data as API calls are made.  By doing this it reduces the need for itterows or additional for loops later in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writer_list(writer, imdb):\n",
    "    final_list = []\n",
    "    name_list = writer.split(',')\n",
    "    for index in name_list:\n",
    "        name = index.split(' (')[0]\n",
    "        final_list.append({'imdb_id' : imdb,\n",
    "                         'first_name' : name.rsplit(' ', 1)[0],\n",
    "                         'last_name' : name.split()[-1]})\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_list(name_string, imdb):\n",
    "    final_list = []\n",
    "    name_list = name_string.split(',')\n",
    "    for index in name_list:\n",
    "        final_list.append({'imdb_id' : imdb,\n",
    "                               'first_name' : index.rsplit(' ', 1)[0],\n",
    "                               'last_name' : index.split()[-1]})\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API calls and parsing by use of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"http://www.omdbapi.com//?i=\"\n",
    "api = f\"&apikey={api_key}\"\n",
    "actor_data = []\n",
    "director_data = []\n",
    "writer_data = []\n",
    "awards_data = []\n",
    "ratings_data = []\n",
    "\n",
    "for id_ in tqdm_notebook(imdb_id):\n",
    "    try:\n",
    "        response = requests.get(url + id_+api).json()\n",
    "    except JSONDecodeError:\n",
    "        print(f'error at {id_}')\n",
    "        response = requests.get(url + id_+api).json()\n",
    "    try:\n",
    "        director = response['Director']\n",
    "        temp_list = process_list(director, id_)\n",
    "        for item in temp_list:\n",
    "             director_data.append(item)\n",
    "        actor = response['Actors']\n",
    "        temp_list = process_list(actor, id_)\n",
    "        for item in temp_list:\n",
    "             actor_data.append(item)\n",
    "        writer = response['Writer']\n",
    "        temp_list = writer_list(writer, id_)\n",
    "        for item in temp_list:\n",
    "             writer_data.append(item)\n",
    "        rating = response['Rated']\n",
    "        ratings_data.append({'imdb_id' : id_,\n",
    "                             'ratings' : rating})\n",
    "        award = response['Awards']\n",
    "        awards_data.append({'imdb_id' : id_,\n",
    "                            'awards' : award})\n",
    "    except KeyError:\n",
    "        print(f'KeyError at {id_}')\n",
    "        director_data.append({'imdb_id' : id_,\n",
    "                         'first_name' : 'No Data',\n",
    "                         'last_name' : 'No Data'})\n",
    "        actor_data.append({'imdb_id' : id_,\n",
    "                         'first_name' : 'No Data',\n",
    "                         'last_name' : 'No Data'})\n",
    "        writer_data.append({'imdb_id' : id_,\n",
    "                         'first_name' : 'No Data',\n",
    "                         'last_name' : 'No Data'})\n",
    "        awards_data.append({'imdb_id' : id_,\n",
    "                            'awards' : 'No Data'})\n",
    "        ratings_data.append({'imdb_id' : id_,\n",
    "                             'ratings' : 'No Data'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert list of dictionaries to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_all_df = pd.DataFrame(actor_data)\n",
    "writer_all_df = pd.DataFrame(writer_data)\n",
    "director_all_df = pd.DataFrame(director_data)\n",
    "ratings_all_df = pd.DataFrame(ratings_data)\n",
    "awards_all_df = pd.DataFrame(awards_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace blanks left by individuals with only one name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_all_df.replace('', 'N/A', inplace = True)\n",
    "writer_all_df.replace('', 'N/A', inplace = True)\n",
    "director_all_df.replace('', 'N/A', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create individual DataFrames which will then be pushed to the database as tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_actor_id_df = actor_all_df\n",
    "actor_id = film_actor_id_df.groupby(['last_name', 'first_name']).ngroup()\n",
    "film_actor_id_df['actor_id'] = actor_id\n",
    "film_actor_id_df['actor_id'] = 'a' + film_actor_id_df['actor_id'].astype(str)\n",
    "film_actor_df = film_actor_id_df.drop(['first_name', 'last_name'], axis=1)\n",
    "film_actor_df.drop_duplicates(subset=['imdb_id', 'actor_id'], inplace = True)\n",
    "actor_df = film_actor_id_df.drop(['imdb_id'], axis=1)\n",
    "actor_df.drop_duplicates(subset='actor_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_writer_id_df = writer_all_df\n",
    "writer_id = film_writer_id_df.groupby(['last_name', 'first_name']).ngroup()\n",
    "film_writer_id_df['writer_id'] = writer_id\n",
    "film_writer_id_df['writer_id'] = 'w' + film_writer_id_df['writer_id'].astype(str)\n",
    "film_writer_df = film_writer_id_df.drop(['first_name', 'last_name'], axis=1)\n",
    "film_writer_df.drop_duplicates(subset=['imdb_id', 'writer_id'], inplace = True)\n",
    "writer_df = film_writer_id_df.drop(['imdb_id'], axis=1)\n",
    "writer_df.drop_duplicates(subset='writer_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_director_id_df = director_all_df\n",
    "director_id = film_director_id_df.groupby(['last_name', 'first_name']).ngroup()\n",
    "film_director_id_df['director_id'] = director_id\n",
    "film_director_id_df['director_id'] = 'd' + film_director_id_df['director_id'].astype(str)\n",
    "film_director_df = film_director_id_df.drop(['first_name', 'last_name'], axis=1)\n",
    "film_director_df.drop_duplicates(subset=['imdb_id', 'director_id'], inplace = True)\n",
    "director_df = film_director_id_df.drop(['imdb_id'], axis=1)\n",
    "director_df.drop_duplicates(subset='director_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_ratings_df = ratings_all_df.drop_duplicates(subset=['imdb_id', 'ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_awards_df = awards_all_df.drop_duplicates(subset=['awards', 'imdb_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm table structure and headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_actor_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_writer_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_director_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code can be used to call data from csv files to save time of making API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_df_data = \"Data/actor_df.csv\"\n",
    "# actor_df = pd.read_csv(actor_df_data, low_memory=False)\n",
    "\n",
    "# director_df_data = \"Data/director_df.csv\"\n",
    "# director_df = pd.read_csv(director_df_data, low_memory=False)\n",
    "\n",
    "# writer_df_data = \"Data/writer_df.csv\"\n",
    "# writer_df = pd.read_csv(writer_df_data, low_memory=False)\n",
    "\n",
    "# film_actor_df_data = \"Data/film_actor_df.csv\"\n",
    "# film_actor_df = pd.read_csv(film_actor_df_data, low_memory=False)\n",
    "\n",
    "# film_director_df_data = \"Data/film_director_df.csv\"\n",
    "# film_director_df = pd.read_csv(film_director_df_data, low_memory=False)\n",
    "\n",
    "# film_writer_df_data = \"Data/film_writer_df.csv\"\n",
    "# film_writer_df = pd.read_csv(film_writer_df_data, low_memory=False)\n",
    "\n",
    "# film_ratings_df_data = \"Data/film_ratings_df.csv\"\n",
    "# film_ratings_df = pd.read_csv(film_ratings_df_data, low_memory=False)\n",
    "\n",
    "# film_awards_df_data = \"Data/film_awards_df.csv\"\n",
    "# film_awards_df = pd.read_csv(film_awards_df_data, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate connection to database and verify tables present in database - insert your postgress username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_connection_string = \"<enter-username>:<enter-password>@localhost:5432/movies_db\"\n",
    "engine = create_engine(f'postgresql://{rds_connection_string}')\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push DataFrames to the database as tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_df.to_sql(name='actor', con=engine, if_exists='append', index=False)\n",
    "director_df.to_sql(name='director', con=engine, if_exists='append', index=False)\n",
    "writer_df.to_sql(name='writer', con=engine, if_exists='append', index=False)\n",
    "film_actor_df.to_sql(name='film_actor', con=engine, if_exists='append', index=False)\n",
    "film_director_df.to_sql(name='film_director', con=engine, if_exists='append', index=False)\n",
    "film_writer_df.to_sql(name='film_writer', con=engine, if_exists='append', index=False)\n",
    "film_ratings_df.to_sql(name='film_rating', con=engine, if_exists='append', index=False)\n",
    "film_awards_df.to_sql(name='film_awards', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create csv files for later use if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_df.to_csv('actor_df.csv', index=False)\n",
    "# director_df.to_csv('director_df.csv', index=False)\n",
    "# writer_df.to_csv('writer_df.csv', index=False)\n",
    "# film_actor_df.to_csv('film_actor_df.csv', index=False)\n",
    "# film_director_df.to_csv('film_director_df.csv', index=False)\n",
    "# film_writer_df.to_csv('film_writer_df.csv', index=False)\n",
    "# film_ratings_df.to_csv('film_ratings_df.csv', index=False)\n",
    "# film_awards_df.to_csv('film_awards_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
